#!/usr/bin/env sh
#
# BSD 2-Clause License
# 
# Copyright (c) 2023, Justin Teague
# 
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
# 
# 1. Redistributions of source code must retain the above copyright notice, this
#    list of conditions and the following disclaimer.
# 
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# rssntfy -- send notifications to ntfy.sh service when an rss feed updates

set -eu

LC_ALL=C

Prgnam="$(basename "$0")"
Ntfy_Server="${Ntfy_Server:=https://ntfy.sh}"
Ntfy_Topic=""
Ntfy_Priority="${Ntfy_Priority:=3}"
Working_Dir="${Working_Dir:=$HOME/.local/var/$Prgnam}"

Verbose=0
Quiet_Mode=0
Debug_Mode=0

# Function: Output usage
# Arguments: exit status
usage() (
  cat << EOF
  Usage: $Prgnam [-Dhqv] [OPTIONS] url://rss.feed.xml

  Arguments:
  -D        Debug mode (do not send to ntfy)
  -h        This screen.
  -q        Quiet output, errors only.
  -v        Verbose logging

  Options:
  -t        Topic for ntfy.sh (Optional)
  -p        Priority [1-5] (Default: 3)
  -s        ntfy.sh server url (Default: https://ntfy.sh)

  Example:
  To monitor 3 RSS feeds under one ntfy.sh topic (e.g., RssNewsTechTag),
  set the following as as a cron job:

  $Prgnam -t RssNewsTechTag \\
             https://feeds.arstechnica.com/arstechnica/index \\
             theverge.com \\
             pcmag.com

EOF
)

# Function: check if string is an integer
# Argument: string
is_int() {
  printf %d "$1" >/dev/null 2>&1
}

# Function: output log data to stderr
# Arguments: message
log() (
  priority=1
  if is_int "$1"; then
    priority="$1"
    shift
  fi

  if [ "$Verbose" -ge "$priority" ]; then
    printf '[%s]: %s\n' "$(date +'%Y-%m-%dT%H:%M:%S%z')" "$*" >&2
  fi

)

# Function: output error data to stderr
# Arguments: message
err() (
  printf '[%s]: ERROR %s\n' "$(date +'%Y-%m-%dT%H:%M:%S%z')" "$*" >&2
)

# Function: remove HTML special characters from a string
# Argument: string
shortcodify() (
  # shellcheck disable=SC2086
  set -f
  old_ifs=$IFS
  IFS="\"'&<>,.()/ "
  # shellcheck disable=2086
  set -- $1
  while [ "$#" -gt 1 ]; do
    printf '%s-' "$1"
    shift
  done
  printf %s\\n "$1"
  IFS=$old_ifs
)

# Function: output the checksum of a string
# Arguments: string
hash_sum() (
  hash=""
  if ! command -v cksum >/dev/null 2>&1; then
    printf "cksum not found in path\n"
    return 1
  fi

  if ! hash="$(printf '%s' "$*" | cksum 2>&1)"; then
    printf %s\\n "$hash"
    return 1
  fi
  a=${hash%\ *}
  b=${hash#*\ }
  hash=$((a + b))
  hash=$((hash + (hash << 6) + (hash << 16) - hash))

  printf %d\\n $hash 2>&1
)

# Function: make a curl request and return a file
# Arguments: Same as you would with curl, less -sS options
http__curl() (
  retval=0 response="" ret=""
  if ! command -v curl >/dev/null 2>&1; then
    printf 'curl not found in path\n'
    return 1
  fi

  if ! response=$(mktemp 2>&1); then
    printf %s\\n "$response"
    return 1
  fi

  if ! ret=$("$(command -v curl)" -sSL \
    -o "$response" \
    -w '%{http_code}' \
    "$@" 2>&1); then
      printf %s\\n "$ret" > "$response"
      retval=1
  fi

  if [ $retval -eq 0 ] && [ "$ret" -ge 400 ]; then
    printf 'HTTP Error Code: %s\n' "$ret"
    retval=1
  fi

  cat "$response"
  rm -rf "$response"
  return $retval
)

# Function: replace UTF character encodings
# Argument: string
utf_char_decode() (
  # first check and then return if not found
  code="" char=""
  case "$1" in
    *\\u0036*)
      code='\u0036'
      char='&'
      ;;
    *\\u003c*)
      code='\u003c'
      char="<"
      ;;
    *\\u003e*)
      code='\u003e'
      char=">"
      ;;
    *\\u0022*)
      code='\u0022'
      char='"'
      ;;
    *\\0027*)
      code='\u0027'
      char="'"
      ;;
    *)
      printf %s\\n "$1"
      return
      ;;
  esac

  a="${1%%"$code"*}"
  b="${1##*"$code"}"
  printf %s\\n "$a$char$b"
)

# Function: replace xml character encodings
# Argument: string
xml_char_decode() (
  # first check and then return if not found
  code="" char=""
  case "$1" in
    *\&amp\;*)
      code='&amp;'
      char='&'
      ;;
    *\&lt\;*)
      code='&lt;'
      char="<"
      ;;
    *\&gt\;*)
      code='&gt;'
      char=">"
      ;;
    *\&quot\;*)
      code='&quot;'
      char='"'
      ;;
    *\&apos\;*)
      code='&apos;'
      char="'"
      ;;
    *)
      printf %s\\n "$1"
      return
      ;;
  esac

  a="${1%%"$code"*}"
  b="${1##*"$code"}"
  printf %s\\n "$a$char$b"
)

# Function: clean-up XML data
# Arguments: XML string
cleanup_xml() (
  # xml_char_decode
  xml="$(xml_char_decode "$1")"
  # Remove <![CDATA][*]]>
  case "$xml" in
    *CDATA*)
      xml="${xml##*\<\!\[CDATA\[}"
      xml="${xml%%\]\]\>*}"
      echo "$xml"
      exit
      ;;
  esac
  # return cleaned-up string
  printf %s\\n "$xml"
)

# Function: validate if xml+rss or html; attempts to return xml feed
# Arguments: URL
validate_xml() (
  if ! r="$(http__curl "$1")"; then
    printf %s\\n "$r"
    return 1
  fi

  log 4 "$r"

  # Check if xml feed
  case "$r" in
    \<\?xml\ version*|\<rss\ version*)
      log 3 "$1 appears to be xml or rss feed"
      printf %s\\n "$1"
      return
      ;;
  esac

  # Find xml href in HTML page
  r="${r%%\<\/head\>*}"

  case "$r" in
    *rss+xml*)
      xml="${r#*application/rss+xml\"*href=\"}"
      xml="${xml%%\"*}"
      ;;
    *atom+xml*)
      xml="${r#*application/atom+xml\"*href=\"}"
      xml="${xml%%\"*}"
      ;;
    *)
      err "No xml+rss or xml+atom feeds found at $1"
      printf %s\\n "$1"
      return 1
      ;;
  esac
  
  # fix shortlinks
  case "$xml" in 
    http*)
      log 3 "xml link is --> $xml"
      ;;
    /*)
      xml="${1}$xml"
      log 3 "corrected shortlink is --> $xml"
      ;;
    *)
      xml="${1}/$xml"
      log 3 "corrected shortlink is --> $xml"
      ;; 
  esac

  log 1 "validating $xml"
  if xml="$(validate_xml "$xml")"; then
    printf %s\\n "$xml"
    return
  fi
  
  err "Unable to validate $xml as an xml file"
  printf %s\\n "$1"
  return 1
)

is_atom_feed() (
  case "$1" in
    *\<entry\>*) return 0 ;;
              *) return 1 ;;
  esac
)

main() {
  retval=0
  # Get opts
  while getopts 'qvDht:p:s:' opts; do
    case "$opts" in
      D) Debug_Mode=1 ;;
      q) Quiet_Mode=1 ;;
      v) Verbose=$((Verbose + 1)) ;;
      h) usage ; exit ;;
      t) Ntfy_Topic="$OPTARG" ;;
      p) Ntfy_Priority="$OPTARG" ;;
      s) Ntfy_Server="$OPTARG" ;;
      *) usage ; exit 1 ;;
    esac
  done
  shift "$((OPTIND - 1))"

  if [ "$Quiet_Mode" -eq 1 ]; then
    Verbose=-1
  fi

  log 3 "Debug_Mode --> $Debug_Mode"
  log 3 "Quiet_Mode --> $Quiet_Mode"
  log 3 "Verbose --> $Verbose"
  log 3 "Working_Dir --> $Working_Dir"
  log 3 "Ntfy_Topic --> $Ntfy_Topic"
  log 3 "Ntfy_Priority --> $Ntfy_Priority"
  log 3 "Ntfy_Server --> $Ntfy_Server"

  if [ -z "${1:-}" ]; then
    err "No arguments passed."
    usage
    exit 1
  fi

  # shellcheck disable=2068
  for feed in $@; do

    log 3 "feed is: $feed"
    log 3 "validating $feed"
    if ! feed="$(validate_xml "$feed")"; then
      err "Unable to validate $feed xml"
      retval=$((retval + 1))
      continue
    fi

    log 3 "Post-validated feed is $feed"
    log 2 "Downloading $feed"
    # curl the feed
    if ! xml="$(http__curl "$feed")"; then
      err "Unable to download $feed"
      err "$xml"
      retval=$((retval + 1))
      continue
    fi

    log 2 "Parsing xml for $feed"
    feedName="" itemName="" itemLink=""
    if is_atom_feed "$xml"; then
      log 2 "I think $feed is an atom+xml feed"
      # Channel title
      # Strip everything after first entry tag
      xml="${xml%%\<\/entry\>*}"
      t="${xml%%\<\/title\>*}"
      feedName="${t#*\<title\>}"

      # First item title
      # Strip everything before first entry tag
      xml="${xml##*\<entry\>}"
      i="${xml%%\<\/title\>*}"
      itemName="${i#*\<title\>}"

      # First item link
      l="${xml%%\<\/link\>*}"
      l="${l#*\<link\>}"
      l="${l#*href=\"}"
      itemLink="${l%%\"*}"
    else
      log 2 "I think $feed is an rss+xml feed"
      # Parse RSS feed
      feedName="" itemName="" itemLink=""
      # Channel title
      # Strip everything after first item tag
      xml="${xml%%\<\/item\>*}"
      t="${xml%%\<\/title\>*}"
      feedName="${t#*\<title\>}"

      # First item title
      # Strip everything before first item tag
      xml="${xml##*\<item\>}"
      i="${xml%%\<\/title\>*}"
      itemName="${i#*\<title\>}"

      # First item link
      l="${xml%%\<\/link\>*}"
      itemLink="${l#*\<link\>}"
    fi

    # Check if it worked
    if [ -z "$feedName" ] || [ -z "$itemName" ] || [ -z "$itemLink" ]; then
      err "Unable to parse RSS XML: $feed"
      retval=$((retval + 1))
      continue
    fi

    # Cleanup xml encodings, if found
    feedName="$(cleanup_xml "$feedName")"
    itemName="$(cleanup_xml "$itemName")"
    itemLink="$(cleanup_xml "$itemLink")"

    Ntfy_Topic="${Ntfy_Topic:-"$(shortcodify "$feedName")"}"

    log 3 "Ntfy_Topic -->: $Ntfy_Topic"
    log 3 "feedName --> $feedName"
    log 3 "itemName --> $itemName"
    log 3 "itemLink --> $itemLink"

    # Hashed Ntfy_Topic
    if ! h_name="$(hash_sum "$Ntfy_Topic")"; then
      err "Unable to hash $Ntfy_Topic"
      err "$h_name"
      return $((retval + 1))
    fi
    
    # Hashed Title
    if ! h_feed="$(hash_sum "$feedName")"; then
      err "Unable to hash $feedName"
      err "$h_feed"
      return $((retval + 1))
    fi

    # Hashed Content
    if ! h_content="$(hash_sum "$feedName" "$itemName" "$itemLink")"; then
      err "Unable to hash content: $feedName, $itemName, $itemLink"
      err "$h_content"
      return $((retval + 1))
    fi

    hash_file="$Working_Dir/$h_name/$h_feed"
    if [ -r "$hash_file" ]; then
      if [ "$h_content" -eq "$(cat "$hash_file")" ]; then
        log 1 "'$feedName' is at latest version. Skipping."
        continue
      fi
    fi

    log 1 "'$feedName' has been updated"

    if ! mkdir -p "$(dirname "$hash_file")"; then
      err "FATAL Unable to access $hash_file"
      return $((retval + 1))
    fi

    if ! printf %s\\n "$h_content" > "$hash_file"; then
      err "FATAL Unable to write to $hash_file"
      return $((retval + 1))
    fi

    log 3 "$h_content saved to $hash_file"

    if ! ntfy_shorttopic="$(shortcodify "$Ntfy_Topic")"; then
      err "Unable to shorten $Ntfy_Topic for ntfy.sh; skipping"
      return $((retval + 1))
    fi

    # Check if this message is in ntfy cache
    if ! j="$(http__curl \
              "$Ntfy_Server/$ntfy_shorttopic/json?poll=1")"; then
      err "Unable to check cache for $Ntfy_Server/$ntfy_shorttopic"
      err "$j"
      retval=$((retval + 1))
      continue
    fi

    log 2 "Parsing ntfy json"
    in_cache=0
    # Parse the ntfy json
    while read -r json; do
      cache_title="${json#*\"title\"\:\"}"
      cache_title="${cache_title%%\",*}"
      cache_title="$(utf_char_decode "$cache_title")"
      log 3 "cache_title --> $cache_title"

      cache_msg="${json#*\"message\"\:\"}"
      cache_msg="${cache_msg%%\",*}"
      cache_msg="$(utf_char_decode "$cache_msg")"
      log 3 "cache_msg --> $cache_msg"

      cache_url="${json#*\"url\"\:\"}"
      cache_url="${cache_url%%\"*}"
      cache_url="$(utf_char_decode "$cache_url")"
      log 3 "cache_url --> $cache_url"

      if ! h_cache="$(hash_sum "$cache_title" "$cache_msg" "$cache_url")"; then
        err "Unable to hash $cache_title, $cache_msg, $cache_url"
        err "$h_cache"
        return $((retval + 1))
      fi

      if [ "$h_cache" -eq "$(cat "$hash_file")" ]; then
        in_cache=1
        continue
      fi

      done << EOF
      $(printf %s\\n "$j")
EOF

    if [ "$in_cache" -eq 1 ]; then
      log 1 "$feedName is already in the ntfy cache. Skipping."
      continue
    fi

    if [ "$Debug_Mode" -ne 0 ]; then
      log 0 "Debug Mode: $feedName is updated, but not sending to ntfy."
      continue 
    fi

    log 1 "Sending notification to $Ntfy_Server/$ntfy_shorttopic"
    log 3 "$feedName, $itemLink, $itemName, $itemLink"
    if ! r="$(http__curl \
              "$Ntfy_Server/$ntfy_shorttopic" \
              -H "Title: $feedName" \
              -H "Click: $itemLink" \
              -H "Actions: view, Read, $itemLink" \
              -H "Priority: $Ntfy_Priority" \
              -d "$itemName" )"; then
      err "Unable to post to $Ntfy_Server/$ntfy_shorttopic"
      err "$r"
      retval=$((retval + 1))
      continue
    fi

    log 3 "Response from $Ntfy_Server: $r"

    log 0 "'$feedName' sent to: $Ntfy_Server/$ntfy_shorttopic"

  done
  log 3 "Retval: $retval"
  return "$retval"
} 

main "$@"
